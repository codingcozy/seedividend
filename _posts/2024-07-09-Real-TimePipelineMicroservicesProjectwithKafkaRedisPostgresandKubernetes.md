---
title: "Kafka, Redis, Postgres, Kubernetesë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸ ë°©ë²•"
description: ""
coverImage: "/TIL/assets/img/2024-07-09-Real-TimePipelineMicroservicesProjectwithKafkaRedisPostgresandKubernetes_0.png"
date: 2024-07-09 19:43
ogImage:
  url: /assets/img/2024-07-09-Real-TimePipelineMicroservicesProjectwithKafkaRedisPostgresandKubernetes_0.png
tag: Tech
originalTitle: "Real-Time Pipeline Microservices Project with Kafka, Redis, Postgres, and Kubernetes."
link: "https://medium.com/stackademic/real-time-pipeline-microservices-project-with-kafka-redis-postgres-and-kubernetes-a09e40c20520"
---

# ì†Œê°œ

ì´ ë¬¸ì„œëŠ” ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë¶„ì„ì„ ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì±„ìš°ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì‹¤ì‹œê°„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì•ˆë‚´ì„œì…ë‹ˆë‹¤.

![ì´ë¯¸ì§€](/TIL/assets/img/2024-07-09-Real-TimePipelineMicroservicesProjectwithKafkaRedisPostgresandKubernetes_0.png)

# STG-Service

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

# Redis í´ë¼ì´ì–¸íŠ¸

Redisì™€ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤. íŠ¹ì • í‚¤ë¡œ ê°ì²´ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒˆ í‚¤-ê°’ ìŒì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```js
import json
from typing import Dict
import redis

class RedisClient:
    def __init__(self, host: str, port: int, password: str, cert_path: str) -> None:
        self._client = redis.StrictRedis(
            host=host,
            port=port,
            password=password,
            ssl=True,
            ssl_ca_certs=cert_path)
    def set(self, k, v):
        self._client.set(k, json.dumps(v))
    def get(self, k) -> Dict:
        obj: str = self._client.get(k)
        return json.loads(obj)
```

# Postgres í´ë¼ì´ì–¸íŠ¸

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•˜ëŠ” ê²ƒ ì™¸ì—ë„, í´ë¼ì´ì–¸íŠ¸ëŠ” í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ì˜ ì¼ë¶€ë¡œ ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ í•œ íŠ¸ëœì­ì…˜ì˜ ì‹¤í–‰ ëª…ë ¹ì„ ì»¤ë°‹í•  í•„ìš”ê°€ ì—†ì–´ìš” (ë‚˜ì¤‘ì— ì‚¬ìš© ì˜ˆì œë¥¼ ë³´ê²Œ ë  ê±°ì—ìš”):

```js
from contextlib import contextmanager
from typing import Generator
import psycopg2

class PgConnect:
    def __init__(self, host: str, port: int, db_name: str, user: str, pw: str, sslmode: str = "require") -> None:
        self.host = host
        self.port = port
        self.db_name = db_name
        self.user = user
        self.pw = pw
        self.sslmode = sslmode
    def url(self) -> str:
        return """
            host={host}
            port={port}
            dbname={db_name}
            user={user}
            password={pw}
            target_session_attrs=read-write
            sslmode={sslmode}
        """.format(
            host=self.host,
            port=self.port,
            db_name=self.db_name,
            user=self.user,
            pw=self.pw,
            sslmode=self.sslmode)
    @contextmanager
    def connection(self) -> Generator:
        keepalive_kwargs = {
            "keepalives": 1,
            "keepalives_idle": 30,
            "keepalives_interval": 5,
            "keepalives_count": 5,
        }
        conn = psycopg2.connect(self.url(), **keepalive_kwargs)
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            conn.close()
```

ì¹´í”„ì¹´ì—ì„œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ê³  ì‚¬ìš©í•˜ëŠ” ë‘ ê°œì˜ ë³„ë„ ë° ê°„ë‹¨í•œ í´ë¼ì´ì–¸íŠ¸:

```js
import json
from typing import Dict, Optional
from confluent_kafka import Consumer, Producer

def error_callback(err):
    print('Something went wrong: {}'.format(err))

class KafkaProducer:
    def __init__(self, host: str, port: int, user: str, password: str, topic: str, cert_path: str) -> None:
        params = {
            'bootstrap.servers': f'{host}:{port}',
            'security.protocol': 'SASL_SSL',
            'ssl.ca.location': cert_path,
            'sasl.mechanism': 'SCRAM-SHA-512',
            'sasl.username': user,
            'sasl.password': password,
            'error_cb': error_callback,
        }
        self.topic = topic
        self.p = Producer(params)
    def produce(self, payload: Dict) -> None:
        self.p.produce(self.topic, json.dumps(payload))
        self.p.flush(10)

class KafkaConsumer:
    def __init__(self,
                 host: str,
                 port: int,
                 user: str,
                 password: str,
                 topic: str,
                 group: str,
                 cert_path: str
                 ) -> None:
        params = {
            'bootstrap.servers': f'{host}:{port}',
            'security.protocol': 'SASL_SSL',
            'ssl.ca.location': cert_path,
            'sasl.mechanism': 'SCRAM-SHA-512',
            'sasl.username': user,
            'sasl.password': password,
            'group.id': group,  # '',
            'auto.offset.reset': 'earliest',
            'enable.auto.commit': False,
            'error_cb': error_callback,
            'debug': 'all',
            'client.id': 'someclientkey'
        }
        self.topic = topic
        self.c = Consumer(params)
        self.c.subscribe([topic])
    def consume(self, timeout: float = 3.0) -> Optional[Dict]:
        msg = self.c.poll(timeout=timeout)
        if not msg:
            return None
        if msg.error():
            raise Exception(msg.error())
        val = msg.value().decode()
        return json.loads(val)
```

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

# STG Schema

í¬ìŠ¤íŠ¸ê·¸ë ˆìŠ¤ì˜ ìŠ¤í…Œì´ì§• ë ˆì´ì–´ë¡œ, Kafkaì—ì„œ ë‚˜ì˜¨ ë¡œìš° ë©”ì‹œì§€ë¥¼ ì €ì¥í•  í•œ ê°œì˜ í…Œì´ë¸”ì´ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì•„ë˜ì™€ ê°™ì´ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```js
CREATE SCHEMA IF NOT EXISTS stg;

CREATE TABLE IF NOT EXISTS stg.order_events (
    id SERIAL   PRIMARY KEY,
    object_id   INTEGER NOT NULL UNIQUE,
    object_type VARCHAR(20) NOT NULL,
    sent_dttm   TIMESTAMP NOT NULL,
    payload     JSON NOT NULL
);
```

ê·¸ë¦¬ê³  ì´ë¥¼ ì‹¤í–‰í•  íŒŒì´ì¬ í•¨ìˆ˜ëŠ”:

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

```python
from lib.pg.pg_connect import PgConnect

def make_stg_migrations(db: PgConnect) -> None:
    with db.connection() as conn:
        with conn.cursor() as cur:
            # STG ìŠ¤í‚¤ë§ˆì˜ SQL ì •ì˜ ê²½ë¡œëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            cur.execute(open("stg_schema.sql", "r").read())
```

í”„ë¡œê·¸ë¨ì´ `db.connection()`ìœ¼ë¡œ ì •ì˜ëœ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ ë²—ì–´ë‚˜ë©´ ëª…ì‹œì ìœ¼ë¡œ ì‹¤í–‰í•  í•„ìš” ì—†ì´ ìë™ìœ¼ë¡œ ì»¤ë°‹ë©ë‹ˆë‹¤.

# ë©”ì‹œì§€ ì²˜ë¦¬

ë¨¼ì € ì†Œë¹„ëœ ì¹´í”„ì¹´ ë©”ì‹œì§€ë¥¼ STG í¬ìŠ¤íŠ¸ê·¸ë ˆìŠ¤ í…Œì´ë¸”(StgRepository)ì— ì‚½ì…í•œ ë‹¤ìŒ, ë ˆë””ìŠ¤ì—ì„œ ë ˆìŠ¤í† ë‘ ë°ì´í„°ë¥¼ í’ë¶€í•˜ê²Œí•˜ì—¬ ë‹¤ë¥¸ ì¹´í”„ì¹´ í´ëŸ¬ìŠ¤í„°(StgMessageProcessor)ë¥¼ ìœ„í•œ ì¶œë ¥ ë©”ì‹œì§€ë¥¼ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

```python
from datetime import datetime

from lib.pg.pg_connect import PgConnect

class StgRepository:
    def __init__(self, db: PgConnect) -> None:
        self._db = db

    def order_events_insert(self,
                            object_id: int,
                            object_type: str,
                            sent_dttm: datetime,
                            payload: str
                            ) -> None:
        with self._db.connection() as conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                        INSERT INTO stg.order_events (object_id, object_type, sent_dttm, payload) VALUES (%(object_id)s, %(object_type)s, %(sent_dttm)s, %(payload)s)
                        ON CONFLICT (object_id)
                        DO UPDATE
                        SET object_type = EXCLUDED.object_type,
                            sent_dttm = EXCLUDED.sent_dttm,
                            payload = EXCLUDED.payload;
                    """,
                    {
                        'object_id': object_id,
                        'object_type': object_type,
                        'sent_dttm': sent_dttm,
                        'payload': payload
                    }
                )
```

```python
import json
from datetime import datetime
from logging import Logger
from lib.kafka_connect.kafka_connectors import KafkaConsumer, KafkaProducer
from lib.redis.redis_client import RedisClient
from stg_loader.repository.stg_repository import StgRepository

class StgMessageProcessor:
    def __init__(self,
                 consumer: KafkaConsumer,
                 producer: KafkaProducer,
                 redis: RedisClient,
                 stg_repository: StgRepository,
                 logger: Logger) -> None:
        self._logger = logger
        self._consumer = consumer
        self._producer = producer
        self._redis = redis
        self._stg_repository = stg_repository
        self._batch_size = 100

    def run(self) -> None:
        self._logger.info(f"{datetime.utcnow()}: START")
        for i in range(self._batch_size):
            msg = self._consumer.consume()
            if not msg:
                continue
            self._stg_repository.order_events_insert(object_id=msg["object_id"],
                                                     object_type=msg["object_type"],
                                                     sent_dttm=msg["sent_dttm"],
                                                     payload=json.dumps(msg["payload"]))
            dst_msg = self._construct_output_message(msg)
            self._producer.produce(dst_msg)
        self._logger.info(f"{datetime.utcnow()}: FINISH")

    def _construct_output_message(self, original_message: dict) -> dict:
        restaurant_id = original_message["payload"]["restaurant"]["id"]
        restaurant_data = self._redis.get(restaurant_id)
        restaurant_name = restaurant_data["name"]
        user_id = original_message["payload"]["user"]["id"]
        user_data = self._redis.get(user_id)
        user_name = user_data["name"]
        user_login = user_data["login"]
        order = original_message["payload"]
        restaurant_menu = {p["_id"]: p for p in restaurant_data["menu"]}
        products = {p["id"]: {**p, "category": restaurant_menu[p["id"]]["category"]} for p in order["order_items"]}
        return {
                "object_id": original_message["object_id"],
                "object_type": original_message["object_type"],
                "payload": {
                    "id": original_message["object_id"],
                    "date": order["date"],
                    "cost": order["cost"],
                    "payment": order["payment"],
                    "status": order["final_status"],
                    "restaurant": {
                        "restaurant_id": restaurant_id,
                        "restaurant_name": restaurant_name
                    },
                    "user": {
                        "user_id": user_id,
                        "user_name": user_name,
                        "user_login": user_login
                    },
                    "products": products
                }
            }
```

# ì„œë¹„ìŠ¤ êµ¬ì„±

ì†ŒìŠ¤/ì‹±í¬ ì¹´í”„ì¹´, Redis ë° í¬ìŠ¤íŠ¸ê·¸ë ˆìŠ¤ì™€ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤. ì´ê²ƒì€ í™•ì‹¤íˆ ë§ì€ êµ¬ì„±ì´ í•„ìš”í•˜ë©° í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë¯€ë¡œ ì´ë¥¼ ë³„ë„ì˜ í´ë˜ìŠ¤ì—ì„œ ìˆ˜ìš©í•  ê²ƒì…ë‹ˆë‹¤:

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

```python
import os

from lib.kafka_connect.kafka_connectors import KafkaConsumer, KafkaProducer
from lib.redis.redis_client import RedisClient
from lib.pg.pg_connect import PgConnect
from stg_loader.repository.stg_repository import StgRepository

class AppConfig:
    CERTIFICATE_PATH = '/crt/YandexInternalRootCA.crt'
    DEFAULT_JOB_INTERVAL = 25
    def __init__(self) -> None:
        self.kafka_host = str(os.getenv('KAFKA_HOST') or "")
        self.kafka_port = int(str(os.getenv('KAFKA_PORT')) or 0)
        self.kafka_consumer_username = str(os.getenv('KAFKA_CONSUMER_USERNAME') or "")
        self.kafka_consumer_password = str(os.getenv('KAFKA_CONSUMER_PASSWORD') or "")
        self.kafka_consumer_group = str(os.getenv('KAFKA_CONSUMER_GROUP') or "")
        self.kafka_consumer_topic = str(os.getenv('KAFKA_SOURCE_TOPIC') or "")
        self.kafka_producer_username = str(os.getenv('KAFKA_PRODUCER_USERNAME') or "")
        self.kafka_producer_password = str(os.getenv('KAFKA_PRODUCER_PASSWORD') or "")
        self.kafka_producer_topic = str(os.getenv('KAFKA_DESTINATION_TOPIC') or "")
        self.redis_host = str(os.getenv('REDIS_HOST') or "")
        self.redis_port = int(str(os.getenv('REDIS_PORT')) or 0)
        self.redis_password = str(os.getenv('REDIS_PASSWORD') or "")
        self.pg_host = str(os.getenv('PG_HOST') or "")
        self.pg_port = int(str(os.getenv('PG_PORT')) or 6432)
        self.pg_db_name = str(os.getenv("PG_DB_NAME"))
        self.pg_user = str(os.getenv('PG_USER') or "")
        self.pg_password = str(os.getenv('PG_PASSWORD') or "")
    def kafka_producer(self):
        return KafkaProducer(
            self.kafka_host,
            self.kafka_port,
            self.kafka_producer_username,
            self.kafka_producer_password,
            self.kafka_producer_topic,
            self.CERTIFICATE_PATH
        )
    def kafka_consumer(self):
        return KafkaConsumer(
            self.kafka_host,
            self.kafka_port,
            self.kafka_consumer_username,
            self.kafka_consumer_password,
            self.kafka_consumer_topic,
            self.kafka_consumer_group,
            self.CERTIFICATE_PATH
        )
    def redis_client(self) -> RedisClient:
        return RedisClient(
            self.redis_host,
            self.redis_port,
            self.redis_password,
            self.CERTIFICATE_PATH
        )
    def stg_loader(self) -> StgRepository:
        db: PgConnect = PgConnect(
            self.pg_host,
            self.pg_port,
            self.pg_db_name,
            self.pg_user,
            self.pg_password
        )
        return StgRepository(db)
    def pg_client(self) -> PgConnect:
        return PgConnect(
            self.pg_host,
            self.pg_port,
            self.pg_db_name,
            self.pg_user,
            self.pg_password
        )
```

# STG Service ì‹¤í–‰

StgMessageProcessorë¥¼ ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤ (apscheduler íŒŒì´ì¬ ëª¨ë“ˆì˜ BackgroundSchedulerë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤) ê·¸ë¦¬ê³  ê±´ê°• ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ê°„ë‹¨í•œ APIë¥¼ ì¶”ê°€í•  ê²ƒì…ë‹ˆë‹¤.

```python
import os
import logging

from apscheduler.schedulers.background import BackgroundScheduler
from flask import Flask
from stg_loader.stg_message_processor_job import StgMessageProcessor
from app_config import AppConfig
from stg_migrations import make_stg_migrations

app = Flask(__name__)

# ì„œë¹„ìŠ¤ê°€ ì •ìƒì¸ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
@app.get('/health')
def health():
    return 'healthy'

if __name__ == '__main__':
    app.logger.setLevel(logging.DEBUG)
    config = AppConfig()
    make_stg_migrations(config.pg_client())
    proc = StgMessageProcessor(logger=app.logger,
                               consumer=config.kafka_consumer(),
                               producer=config.kafka_producer(),
                               redis=config.redis_client(),
                               stg_repository=config.stg_loader())
    scheduler = BackgroundScheduler()
    scheduler.add_job(func=proc.run, trigger="interval", seconds=config.DEFAULT_JOB_INTERVAL)
    scheduler.start()
    app.run(debug=True, host='0.0.0.0', use_reloader=False)
```

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

# Dockerfile

ìŠ¤í…Œì´ì§• ì„œë¹„ìŠ¤ëŠ” ì½”ì–´í¬ë ˆì´íŠ¸ ê¸°ë°˜ì˜ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰ë  ì˜ˆì •ì´ë¯€ë¡œ, ì„œë¹„ìŠ¤ë¥¼ ë„ì»¤ ì´ë¯¸ì§€ë¡œ ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.

```js
FROM python:3.10

RUN apt-get update -y
# ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ confluent_kafka íŒŒì´ì¬ ëª¨ë“ˆì´ ì‘ë™ë˜ë„ë¡ í•„ìš”í•©ë‹ˆë‹¤
RUN git clone https://github.com/edenhill/librdkafka && cd librdkafka && ./configure && make && make install && ldconfig
COPY . .
RUN pip install -r requirements.txt
# Kafka í´ëŸ¬ìŠ¤í„°ì— ì•ˆì „í•œ ì—°ê²°ì„ ìœ„í•œ ì¸ì¦ì„œ ë‹¤ìš´ë¡œë“œ
RUN mkdir -p /crt
RUN wget "https://storage.yandexcloud.net/cloud-certs/CA.pem" --output-document /crt/YandexInternalRootCA.crt
RUN chmod 0600 /crt/YandexInternalRootCA.crt
WORKDIR /src
# íŒŒì´ì¬ ì„í¬íŠ¸ê°€ ì‘ë™ë˜ë„ë¡ ì„¤ì •
ENV PYTHONPATH "${PYTHONPATH}:/src"
ENTRYPOINT ["python"]
CMD ["app.py"]
```

ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ Docker Composeë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í…Œì´ì§• ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

```yaml
version: "3.9"

services:
  stg_service:
    build:
      context: .
      network: host
    image: stg_img:local
    container_name: stg_container
    environment:
      FLASK_APP: ${STG_SERVICE_APP_NAME:-stg_service}
      DEBUG: ${STG_SERVICE_DEBUG:-True}
      KAFKA_HOST: ${KAFKA_HOST}
      KAFKA_PORT: ${KAFKA_PORT}
      KAFKA_CONSUMER_USERNAME: ${KAFKA_CONSUMER_USERNAME}
      KAFKA_CONSUMER_PASSWORD: ${KAFKA_CONSUMER_PASSWORD}
      KAFKA_CONSUMER_GROUP: ${KAFKA_CONSUMER_GROUP}
      KAFKA_SOURCE_TOPIC: ${KAFKA_SOURCE_TOPIC}
      KAFKA_DESTINATION_TOPIC: ${KAFKA_DESTINATION_TOPIC}
      KAFKA_PRODUCER_USERNAME: ${KAFKA_PRODUCER_USERNAME}
      KAFKA_PRODUCER_PASSWORD: ${KAFKA_PRODUCER_PASSWORD}
      REDIS_HOST: ${REDIS_HOST}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      PG_HOST: ${PG_HOST}
      PG_PORT: ${PG_PORT}
      PG_DB_NAME: ${PG_DB_NAME}
      PG_USER: ${PG_USER}
      PG_PASSWORD: ${PG_PASSWORD}
    network_mode: "bridge"
    ports:
      - "5101:5000"
    restart: unless-stopped
```

.env íŒŒì¼:

```yaml
KAFKA_HOST=******.mdb.yandexcloud.net
KAFKA_PORT=9091
KAFKA_CONSUMER_USERNAME=producer_consumer
KAFKA_CONSUMER_PASSWORD=******
KAFKA_CONSUMER_GROUP=test-consumer1
KAFKA_SOURCE_TOPIC=dds_input_topic
KAFKA_PRODUCER_USERNAME=producer_consumer
KAFKA_PRODUCER_PASSWORD=*******
KAFKA_DESTINATION_TOPIC=cdm_input_topic

REDIS_HOST=******.mdb.yandexcloud.net
REDIS_PORT=6380
REDIS_PASSWORD=******
PG_HOST=********.mdb.yandexcloud.net
PG_PORT=6432
PG_DB_NAME=sprint9dwh
PG_USER=yandex_pg
PG_PASSWORD=**********
```

# HELM ì°¨íŠ¸

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

Chart.yaml íŒŒì¼:

```yaml
apiVersion: v2
name: first-service
description: ì¿ ë²„ë„¤í‹°ìŠ¤ìš© í—¬ë¦„ ì°¨íŠ¸

# ì°¨íŠ¸ëŠ” 'application' ë˜ëŠ” 'library' ì°¨íŠ¸ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#
# Application ì°¨íŠ¸ëŠ” í…œí”Œë¦¿ ëª¨ìŒì´ë©° ë²„ì „ì´ ì§€ì •ëœ ì•„ì¹´ì´ë¸Œë¡œ íŒ¨í‚¤ì§€í™”í•˜ì—¬ ë°°í¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#
# Library ì°¨íŠ¸ëŠ” ì°¨íŠ¸ ê°œë°œìë¥¼ ìœ„í•œ ìœ ìš©í•œ ìœ í‹¸ë¦¬í‹° ë˜ëŠ” í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Application ì°¨íŠ¸ì˜ ì¢…ì†ì„±ìœ¼ë¡œ í¬í•¨ë˜ì–´
# ë Œë”ë§ íŒŒì´í”„ë¼ì¸ì— ì´ëŸ¬í•œ ìœ í‹¸ë¦¬í‹°ì™€ í•¨ìˆ˜ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤. Library ì°¨íŠ¸ëŠ” í…œí”Œë¦¿ì„ ì •ì˜í•˜ì§€ ì•Šìœ¼ë©° ë”°ë¼ì„œ ë°°í¬ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
type: application
# ì´ê²ƒì€ ì°¨íŠ¸ ë²„ì „ì…ë‹ˆë‹¤. ì´ ë²ˆí˜¸ëŠ” ì°¨íŠ¸ ë° í•´ë‹¹ í…œí”Œë¦¿ì— ë³€ê²½ì´ ìˆì„ ë•Œë§ˆë‹¤ ì¦ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
# ë²„ì „ì€ Semantic Versioning (https://semver.org/)ì„ ë”°ë¥´ëŠ” ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.
version: 0.1.0
# ì´ê²ƒì€ ë°°í¬ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë²„ì „ ë²ˆí˜¸ì…ë‹ˆë‹¤. ì´ ë²„ì „ ë²ˆí˜¸ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë³€ê²½ì´ ìˆëŠ” ê²½ìš°ë§ˆë‹¤ ì¦ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
# ë²„ì „ì€ Semantic Versioningì„ ë”°ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‚¬ìš© ì¤‘ì¸ ë²„ì „ì„ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
# ë”°ì˜´í‘œì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.
appVersion: "1.16.0"
```

values.yaml íŒŒì¼:

```yaml
# ì•±ì˜ ê¸°ë³¸ ê°’.
# ì´ê²ƒì€ YAML í˜•ì‹ì˜ íŒŒì¼ì…ë‹ˆë‹¤.
# í…œí”Œë¦¿ì— ì „ë‹¬í•  ë³€ìˆ˜ë¥¼ ì„ ì–¸í•©ë‹ˆë‹¤.

replicaCount: 3
image:
  # ì»¨í…Œì´ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ëŒ€í•œ ë§í¬. ì•¼Ğ½ë±ìŠ¤ í´ë¼ìš°ë“œì—ì„œ ì‹¤í–‰í•  ê²ƒì…ë‹ˆë‹¤.
  repository: cr.yandex/crpr6naar69761ehm0bp/stg_service
  pullPolicy: IfNotPresent
  # ê¸°ë³¸ì ìœ¼ë¡œ ì°¨íŠ¸ appVersionì¸ ì´ë¯¸ì§€ íƒœê·¸ë¥¼ ë®ì–´ì”ë‹ˆë‹¤.
  tag: "v2022-12-13-r1"
containerPort: 5000
config:
  KAFKA_HOST: rc1a-hins1kp5qsfnsob3.mdb.yandexcloud.net
  KAFKA_PORT: "9091"
  KAFKA_CONSUMER_USERNAME: producer_consumer
  KAFKA_CONSUMER_PASSWORD: "*****"
  KAFKA_CONSUMER_GROUP: test-consumer1
  KAFKA_SOURCE_TOPIC: order-service_orders
  KAFKA_PRODUCER_USERNAME: producer_consumer
  KAFKA_PRODUCER_PASSWORD: "*****"
  KAFKA_DESTINATION_TOPIC: dds_topic_name
  REDIS_HOST: c-c9qeltiiu2rkcr6v9net.rw.mdb.yandexcloud.net
  REDIS_PORT: "6380"
  REDIS_PASSWORD: "*****"
  PG_HOST: rc1b-4olk4uzgdrdte114.mdb.yandexcloud.net
  PG_PORT: "6432"
  PG_DB_NAME: sprint9dwh
  PG_USER: yandex_pg
  PG_PASSWORD: "*****"
imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""
podAnnotations: {}
resources:
  # ì¼ë°˜ì ìœ¼ë¡œ ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ë¥¼ ì§€ì •í•˜ì§€ ì•Šê³  ì‚¬ìš©ìì˜ ëª…ì‹œì ì¸ ì„ íƒìœ¼ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
  # ì´ê²ƒì€ Minikubeì™€ ê°™ì€ ë¦¬ì†ŒìŠ¤ê°€ ì ì€ í™˜ê²½ì—ì„œ ì°¨íŠ¸ ì‹¤í–‰ ê¸°íšŒë¥¼ ë†’ì´ê¸°ë„ í•©ë‹ˆë‹¤.
  # ë¦¬ì†ŒìŠ¤ë¥¼ ì§€ì •í•˜ë ¤ë©´ ì•„ë˜ ì¤„ ì£¼ì„ ì²˜ë¦¬ë¥¼ í•´ì œí•˜ê³  í•„ìš”ì— ë§ê²Œ ì¡°ì •í•œ ë‹¤ìŒ 'resources:' ë’¤ì˜ ì¤‘ê´„í˜¸ë¥¼ ì œê±°í•˜ì„¸ìš”.
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi
```

<!-- TIL ìˆ˜í‰ -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

```yaml
templates/configmap.yamlì€ ìš°ë¦¬ ì„œë¹„ìŠ¤ì˜ êµ¬ì„±ì„ ì €ì¥í•˜ëŠ” k8s ì—”í„°í‹°ì…ë‹ˆë‹¤. values.yaml íŒŒì¼ì˜ config ë¸”ë¡ì—ì„œ ëª¨ë“  í‚¤-ê°’ ìŒì„ ê°€ì ¸ì˜¬ ê²ƒì…ë‹ˆë‹¤:

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "app.fullname" . }}-config
  labels:
    {{- include "app.labels" . | nindent 4 }}
{{- with .Values.config }}
data:
  {{- toYaml . | nindent 2 }}
{{- end }}

templates/deployment.yaml íŒŒì¼

apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "app.fullname" . }}
  labels:
    {{- include "app.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "app.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "app.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          envFrom:
            - configMapRef:
                name: {{ include "app.fullname" . }}-config
          ports:
            - name: http
              containerPort: {{ .Values.containerPort }}
              protocol: TCP
          resources:
            {{- toYaml .Values.resources | nindent 12 }}

<!-- TIL ìˆ˜í‰ -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

STG-Serviceì˜ ì†ŒìŠ¤ ì½”ë“œëŠ” ì—¬ê¸°ì—ì„œ ì°¾ì„ ìˆ˜ ìˆì–´ìš”.

# DDS-Service

STG-Service ì´í›„ì˜ ëª¨ë“  ê²ƒì€ ì‹¤ì œë¡œ ë§¤ìš° ì‰¬ì›Œì§‘ë‹ˆë‹¤. ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë“¤ë„ ê±°ì˜ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì´ì£ . DDS-Serviceì˜ ê²½ìš°, ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì •ì˜ê°€ ë™ì¼í•©ë‹ˆë‹¤. Dockerfile, Docker Compose ë° HELM ChartëŠ” ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ì†ŒìŠ¤ ì½”ë“œë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.

ê°€ì¥ í° ì°¨ì´ì ì€ ë°ì´í„° ëª¨ë¸ë§ ë°©ì‹ì— ìˆìŠµë‹ˆë‹¤ (Data Vault 2.0ì„ ì‚¬ìš©í•©ë‹ˆë‹¤):

<!-- TIL ìˆ˜í‰ -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

CREATE SCHEMA IF NOT EXISTS dds;

-- ë°ì´í„° ë³´íŠ¸ --
-- í—ˆë¸Œ --
CREATE TABLE IF NOT EXISTS dds.h_user (
    h_user_pk UUID PRIMARY KEY,
    user_id   VARCHAR NOT NULL UNIQUE,
    load_dt   TIMESTAMP NOT NULL,
    load_src  VARCHAR NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.h_product (
    h_product_pk UUID PRIMARY KEY,
    product_id   VARCHAR NOT NULL UNIQUE,
    load_dt      TIMESTAMP NOT NULL,
    load_src     VARCHAR NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.h_category (
    h_category_pk UUID PRIMARY KEY,
    category_name VARCHAR NOT NULL UNIQUE,
    load_dt       TIMESTAMP NOT NULL,
    load_src      VARCHAR NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.h_restaurant (
    h_restaurant_pk UUID PRIMARY KEY,
    restaurant_id   VARCHAR NOT NULL UNIQUE,
    load_dt         TIMESTAMP NOT NULL,
    load_src        VARCHAR NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.h_order (
    h_order_pk UUID PRIMARY KEY,
    order_id   INTEGER NOT NULL UNIQUE,
    order_dt   TIMESTAMP NOT NULL,
    load_dt    TIMESTAMP NOT NULL,
    load_src   VARCHAR NOT NULL
);
-- í›—ë“¤ --
CREATE TABLE IF NOT EXISTS dds.s_user_names (
    hk_user_names_pk UUID PRIMARY KEY,
    h_user_pk        UUID NOT NULL UNIQUE REFERENCES dds.h_user (h_user_pk),
    username         VARCHAR NOT NULL,
    userlogin        VARCHAR NOT NULL,
    load_src         VARCHAR NOT NULL,
    load_dt          TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.s_product_names (
    hk_product_names_pk UUID PRIMARY KEY,
    h_product_pk        UUID NOT NULL UNIQUE REFERENCES dds.h_product (h_product_pk),
    name                VARCHAR NOT NULL,
    load_src            VARCHAR NOT NULL,
    load_dt             TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.s_restaurant_names (
    hk_restaurant_names_pk UUID PRIMARY KEY,
    h_restaurant_pk        UUID NOT NULL UNIQUE REFERENCES dds.h_restaurant (h_restaurant_pk),
    name                   VARCHAR NOT NULL,
    load_src               VARCHAR NOT NULL,
    load_dt                TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.s_order_cost (
    hk_order_cost_pk UUID PRIMARY KEY,
    h_order_pk       UUID NOT NULL UNIQUE REFERENCES dds.h_order (h_order_pk),
    cost             DECIMAL(19, 5) NOT NULL,
    payment          DECIMAL(19, 5) NOT NULL,
    load_src         VARCHAR NOT NULL,
    load_dt          TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.s_order_status (
    hk_order_status_pk UUID PRIMARY KEY,
    h_order_pk         UUID NOT NULL UNIQUE REFERENCES dds.h_order (h_order_pk),
    status             VARCHAR NOT NULL,
    load_src           VARCHAR NOT NULL,
    load_dt            TIMESTAMP NOT NULL
);
-- ë§í¬ --
CREATE TABLE IF NOT EXISTS dds.l_order_product (
    hk_order_product_pk UUID PRIMARY KEY,
    h_order_pk          UUID NOT NULL REFERENCES dds.h_order (h_order_pk),
    h_product_pk        UUID NOT NULL REFERENCES dds.h_product (h_product_pk),
    load_src            VARCHAR NOT NULL,
    load_dt             TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.l_product_restaurant (
    hk_product_restaurant_pk UUID PRIMARY KEY,
    h_restaurant_pk          UUID NOT NULL REFERENCES dds.h_restaurant (h_restaurant_pk),
    h_product_pk             UUID NOT NULL REFERENCES dds.h_product (h_product_pk),
    load_src                 VARCHAR NOT NULL,
    load_dt                  TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.l_product_category (
    hk_product_category_pk UUID PRIMARY KEY,
    h_category_pk          UUID NOT NULL REFERENCES dds.h_category (h_category_pk),
    h_product_pk           UUID NOT NULL REFERENCES dds.h_product (h_product_pk),
    load_src               VARCHAR NOT NULL,
    load_dt                TIMESTAMP NOT NULL
);
CREATE TABLE IF NOT EXISTS dds.l_order_user (
    hk_order_user_pk UUID PRIMARY KEY,
    h_order_pk       UUID NOT NULL REFERENCES dds.h_order (h_order_pk),
    h_user_pk        UUID NOT NULL REFERENCES dds.h_user (h_user_pk),
    load_src         VARCHAR NOT NULL,
    load_dt          TIMESTAMP NOT NULL
);

ìš°ë¦¬ DDS-Serviceì˜ ì†ŒìŠ¤ Kafka ë©”ì‹œì§€ëŠ” STG-Serviceì˜ ì¶œë ¥ ë©”ì‹œì§€ì…ë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ ì°¨ì´ì ì€ Postgresì— ì´ëŸ¬í•œ ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” ë°©ì‹ì— ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ë³´íŠ¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì•½ê°„ ë³µì¡í•´ì§‘ë‹ˆë‹¤:

import os
import uuid
from datetime import datetime

from lib.pg.pg_connect import PgConnect
from psycopg2.extras import execute_batch

class DdsRepository:
    def __init__(self, db: PgConnect) -> None:
        self._db = db
        self._batch_size = 20
    def h_user_insert(self, user_id: str) -> None:
        with self._db.connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO dds.h_user (h_user_pk, user_id, load_dt, load_src) VALUES (%(h_user_pk)s, %(user_id)s, %(load_dt)s, %(load_src)s)
                    ON CONFLICT (user_id)
                    DO NOTHING;
                """,
                {
                    "h_user_pk": str(uuid.uuid4()),
                    "user_id": user_id,
                    "load_dt": datetime.now(),
                    "load_src": str(os.getenv('KAFKA_SOURCE_TOPIC') or "")
                })
    def s_user_names_insert(self, user_id: str, username: str, userlogin: str) -> None:
        with self._db.connection() as conn:
            with conn.cursor() as cur:
                cur.execute(f"SELECT h_user_pk FROM dds.h_user WHERE user_id = '{user_id}'")
                h_user_pk = cur.fetchone()[0]
                cur.execute("""
                    INSERT INTO dds.s_user_names (hk_user_names_pk, h_user_pk, username, userlogin, load_dt, load_src) VALUES (%(hk_user_names_pk)s, %(h_user_pk)s, %(username)s, %(userlogin)s, %(load_dt)s, %(load_src)s)
                    ON CONFLICT (h_user_pk)
                    DO NOTHING;
                """,
                {
                    "hk_user_names_pk": str(uuid.uuid4()),
                    "h_user_pk": h_user_pk,
                    "username": username,
                    "userlogin": userlogin,
                    "load_dt": datetime.now(),
                    "load_src": str(os.getenv('KAFKA_SOURCE_TOPIC') or "")
                })
    def h_order_insert(self, order_id: str, order_dt: datetime) -> None:
        with self._db.connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO dds.h_order (h_order_pk, order_id, order_dt, load_dt, load_src) VALUES (%(h_order_pk)s, %(order_id)s, %(order_dt)s, %(load_dt)s, %(load_src)s)
                    ON CONFLICT (order_id)
                    DO NOTHING;
                """,
                {
                    "h_order_pk": str(uuid.uuid4()),
                    "order_id": order_id,
                    "order_dt": order_dt,
                    "load_dt": datetime.now(),
                    "load_src": str(os.getenv('KAFKA_SOURCE_TOPIC') or "")
                })
    def s_order_cost_insert(self, order_id: str, cost: float, payment: float) -> None:
        with self._db.connection() as conn:
            with conn.cursor() as cur:
                cur.execute(f"SELECT h_order_pk FROM dds.h_order WHERE order_id = '{order_id}'")
                h_order_pk = cur.fetchone()[0]
                cur.execute("""
                    INSERT INTO dds.s_order_cost (hk_order_cost_pk, h_order_pk, cost, payment, load_dt, load_src) VALUES (%(hk_order_cost_pk)s, %(h_order_pk)s, %(cost)s, %(payment)s, %(load_dt)s, %(load_src)s)
                    ON CONFLICT (h_order_pk)
                    DO UPDATE SET cost = EXCLUDED.cost,
                                  payment = EXCLUDED.payment;
                """,
                {
                    "hk_order_cost_pk": str(uuid.uuid4()),
                    "h_order_pk": h_order_pk,
                    "cost": cost,
                    "payment": payment,
                    "load_dt": datetime.now(),
                    "load_src": str(os.getenv('KAFKA_SOURCE_TOPIC') or "")
                })
    def s_order_status_insert(self, order_id: str, status: str) -> None:
        with self._db.connection() as conn:
            with conn.cursor() as cur:
                cur.execute(f"SELECT h_order_pk FROM dds.h_order WHERE order_id = '{order_id}'")
                h_order_pk = cur.fetchone()[0]
                cur.execute("""
                    INSERT INTO dds.s_order_status (hk_order_status_pk, h_order_pk, status, load_dt, load_src) VALUES (%(hk_order_status_pk)s, %(h_order_pk)s, %(status)s, %(load_dt)s, %(load_src)s)
                    ON CONFLICT (h_order_pk)
                    DO UPDATE SET status=EXCLUDED.status;
                """,
                {
                    "hk_order_status_pk": str(uuid.uuid4()),
                    "h_order_pk": h_order_pk,
                    "status": status,
                    "load_dt": datetime.now(),
                    "load_src": str(os.getenv('KAFKA_SOURCE_TOPIC') or "")
                })
    def l_order_user_insert(self, user_id: str, order_id:

<!-- TIL ìˆ˜í‰ -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

ìš°ë¦¬ëŠ” ìˆ˜ì‹  ë©”ì‹œì§€ë¥¼ HUB, SATELLITE ë° LINKë¡œ ë¶„í• í•©ë‹ˆë‹¤ - ì´ëŠ” ìš°ë¦¬ ë°ì´í„° ëª¨ë¸ì˜ ì£¼ìš” ê°œì²´ì…ë‹ˆë‹¤. ë˜í•œ, ë§ˆì§€ë§‰ ë‹¨ê³„ë¡œ, ë©”ì‹œì§€ë¥¼ ì¶œë ¥ Kafka í´ëŸ¬ìŠ¤í„°ë¡œ ì¤€ë¹„í•˜ì—¬ ë‹¤ìŒ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì„œë¹„ìŠ¤ì— ì „ë‹¬í•©ë‹ˆë‹¤.

app.py íŒŒì¼ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë™ì¼í•©ë‹ˆë‹¤: ì„œë¹„ìŠ¤ë¥¼ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ì„œë¹„ìŠ¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ APIë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

# CDM-Service

ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë“¤ê³¼ ìœ ì‚¬í•˜ê²Œ ì‘ë™í•˜ë©° ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<!-- TIL ìˆ˜í‰ -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4877378276818686"
     data-ad-slot="1549334788"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

# ìŠ¤íƒì•„ë°ë¯¹ ğŸ“

ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ë– ë‚˜ì‹œê¸° ì „ì—:

- ì‘ê°€ë¥¼ í´ë©í•˜ê³  íŒ”ë¡œìš°í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤! ğŸ‘
- ì €í¬ë¥¼ íŒ”ë¡œìš°í•´ì£¼ì„¸ìš”: X | LinkedIn | YouTube | Discord
- ì €í¬ ë‹¤ë¥¸ í”Œë«í¼ë„ ë°©ë¬¸í•´ì£¼ì„¸ìš”: In Plain English | CoFeed | Differ
- ìŠ¤íƒì•„ë°ë¯¹ë‹·ì»´ì—ì„œ ë” ë§ì€ ì½˜í…ì¸ ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”
```
