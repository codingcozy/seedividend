---
title: "Kubernetes 복잡성 해결하기 파트 I"
description: ""
coverImage: "/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_0.png"
date: 2024-05-15 03:38
ogImage: 
  url: /assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_0.png
tag: Tech
originalTitle: "Navigating Kubernetes Complexity (Part I)"
link: "https://medium.com/pipedrive-engineering/navigating-kubernetes-complexity-part-i-37781d4b3ecf"
---


요즘 몇 년 동안 K8s 클러스터의 성장을 목격했습니다. 종종 서비스와 그를 사용하는 기업들... 실패하고 있다는 것을 보게 됩니다. 이러한 애플리케이션들은 작게 시작하여 유기적으로 성장하고 나중에는 느려지기 시작합니다. 디버깅 복잡성이 증가하고, 고객들이 짜증을 내며 불평을 하기 시작하고, 기업들은 성장 문제를 경험하며 등장했을 때와 같이 빠르게 사라지기도 합니다. 어떻게?!? 왜!?! 이 시리즈는 기업이 쿠버네티스 클러스터를 관리할 때 직면하는 어려움을 분석하여 실용적인 솔루션과 전문가의 통찰을 제공합니다. 지수적인 콜 수를 완화하고 소켓 이벤트 트래픽을 제어하는 등 각 기사는 성능을 최적화하고 안정성을 유지하는데 도움이 되는 선제적인 전략을 독자들에게 제공합니다.

![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_0.png)

K8s의 문제의 근본 원인은 매우 간단합니다: 복잡성! 그리고 우리는 개발자들을 탓할 수 없습니다 - K8s 위에 구축된 애플리케이션들은 일반적인 애플리케이션이 아니라 복잡한 분산 앱의 일부입니다. 분산 시스템은 쿠버네티스 클러스터 내에서 몇 백 개의 서비스만 작동하는 것보다 훨씬 복잡하며, 전반적인 그림을 파악하기는 매우 어려울 수 있습니다.

![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_1.png)



보통 시스템이 발전할수록 복잡성이 기하급수적으로 증가합니다. 특정 시기에는 내부 또는 외부 요청으로 인해 클러스터에 엄청난 부하가 걸리게 됩니다.

나는 K8s를 좋아해요. 나의 의도는 그것을 깎아내릴 수 있는 것이 아니라, 실제 시스템에서 발생하는 상황들과 그 원인, 그리고 어떻게 방지할 수 있는지를 함께 알아보는 것입니다.

# 1. 기하급수적 호출 수를 줄이기

대부분의 K8s 앱은 다양한 서비스로 구성되어 있으며, 여기에 일반적인 앱 관리 서비스도 포함됩니다. 다음은 그 예시입니다:



- Customers — 고객 상태 및 계획 확인
- Users — 사용자 상태 확인
- Permissions — 권한 관리

이러한 공유 서비스들은 일반적으로 여러 서비스가 요청하여 해당 고객을 대신하여 작업을 중지해야 하는지 확인합니다. 이는 수신 요청 및 내부 서비스에도 적용됩니다.

그래서, 다른 서비스를 호출할 수 있는 API 서비스를 만든다면, 간단한 요청이 여러 요청으로 변할 수 있습니다.

![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_2.png)



예를 들어, 들어오는 요청(n)이 첫 번째 레벨에서 다섯 개의 요청(#1, #2, #3, #5, #7)을 생성하고 두 번째 레벨에서 세 개의 추가 요청(#4, #6, #8)을 생성했다고 가정해보겠습니다. 생성된 총 요청 수는 n*8가 될 것입니다. 이것은 매우 간단한 예시입니다. 코드를 깊게 파헤쳐보면 숨겨진 요청들 (DNS, 데이터베이스 쿼리, API 등)을 발견할 수 있을 것입니다.

모든 것을 측정하면 여러분의 애플리케이션이 예상 이상으로 기하급수적으로 복잡함을 발견할 수 있을 것입니다.

요청의 지수적인 효과는 초기 요청보다 여덟 배 더 큰 내부 부하를 만들어 낼 수 있으며, 이는 우리 앱을 다운시킬 수 있습니다.

수식을 해봅시다: 클러스터가 120만 개의 내부 요청을 처리할 수 있다고 가정해봅시다. 매일 클러스터는 10만 개의 외부 요청을 처리하고, 이는 내부 요청을 여덟 배 더 생성합니다 (대략 80만 개의 내부 요청). 이는 클러스터에 추가로 40만 개의 내부 요청을 처리할 여유가 있다는 것을 의미합니다. 이는 상당히 크게 느껴질 수 있지만, 추가로 5만 개의 외부 요청이 더 들어오면 한계점에 다다를 수 있습니다. 더 흥미로운 사실은 각 내부 요청을 줄일수록 한계점과의 거리가 멀어진다는 것인데, 이는 더 작은 자원으로 더 많은 일을 처리하면서 지수적인 증가를 줄일 수 있다는 것을 의미합니다.



현재로서는 로드가 더 이상 비선형이 아니라 지수적입니다. 추가 요청 몇 개만으로도 앱의 일부가 다운되거나 응답하지 않고 불안정해질 수 있습니다.

이런 일이 일어나지 않도록 어떻게 할 수 있을까요? 다행히 우리가 시도해볼 수 있는 몇 가지 쉬운 전략이 있습니다.

## 컨텍스트 전파 사용

컨텍스트 전파를 사용하면 요청 사이에서 재사용 가능한 정보를 헤더를 통해 주입하고 전파할 수 있습니다. 이를 통해 모든 서비스가 동일한 데이터를 요청하는 대신 요청을 만드는 모든 서비스로 데이터 집합을 전파할 수 있습니다.

일부캐시(near caches)가 익숙할 것입니다. 데이터는 수명이 몇 초간 유지되는 TTL(time-to-live)을 가집니다. 우리는 요청의 시작 시간 초과에 맞게 TTL이 설정된 헤더에서 데이터 전달의 소스로서 컨텍스트 전파를 사용할 수 있습니다. TTL이 만료되면 클라이언트는 데이터를 새로 고침하고 그 후손 자식 요청으로 전파하기 전에 데이터를 갱신할 수 있어야 합니다. 이를 통해 헤더가 Kafka와 같은 다른 시스템으로 전파될 수 있습니다.

예를 들어 고객 정보(#2)를 자식 요청으로 전파하면 하류에서 세 개의 요청을 절약할 수 있습니다.




![Screenshot 1](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_3.png)

This lets you propagate a previous request downstream:

![Screenshot 2](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_4.png)

## Apply near caching




일반적인 모범 사례에 따르면 정보 제공 서비스는 캐싱과 데이터 관리에 책임을 져야 합니다. 그러나 네이어 캐시는 높은 호출량을 갖는 API에 필수적입니다. 왜냐하면 우리는 보통 같은 메서드를 반복적으로 호출하기 때문이죠. 인스턴스를 확장할 수는 있지만, 아무 것도 무한정으로 확장되지는 않습니다. 그래서 네이어 캐싱을 통해 클러스터를 안정화할 수 있습니다.

네이어 캐싱은 단명한 (가끔 몇 초 동안 유지되는) 클라이언트 측 캐시를 이용한 기술입니다. 만약 일반적인 HTTP 클라이언트에서 전역 캐싱 정책을 정의한다면, 모든 서비스에서 공통 요청에 대해 그 정책을 사용할 수 있습니다. 이는 이미 포화된 인프라에서 요청을 번들로 처리하고 비용을 상당히 절감할 수 있습니다.

요청은 보통 묶음으로 들어옵니다. 고객이 페이지를 로드하기 시작하면, 여러 요청이 일어납니다. 현재 요청 이전에 몇 개의 요청이 이미 이루어졌다면(예: 이 예시에서의 #1 및 #2), 저희의 캐시는 이미 워밍업되어 있기 때문에 다음 요청에서 그 정보를 재활용하여 일부 호출을 절약할 수 있습니다.

그래서 대규모에서 매우 단순한 기술을 사용하여 8개 중 5개의 호출을 절약했습니다. 믿어주세요, 실제 시스템은 이 예시보다 훨씬 복잡하기 때문에 혜택은 더 커질 수 있습니다. 복잡성을 줄이고 지수적인 증가를 최소화하여 8개 중 5개의 요청을 절약했습니다.


## 호출 추적 로깅

호출 추적을 로깅하면 요청의 시작부터 끝까지의 단계를 감지하고 분석할 수 있으며 어떤 호출이 이루어지는지 볼 수 있습니다. Grafana Tempo는 여러분의 추적을 저장하고 조회할 수 있는 솔루션 중 하나입니다.



아래는 마크다운 포맷으로 변경해 드릴게요.


![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_6.png)

## 대량 요청 실행

동일한 API를 여러 번 호출해야 할 경우, 리소스를 절약하고 네트워크 시간을 절약하기 위해 한 번에 모두 요청하세요.

## 요청 속도 제한 (HTTP 429 '요청이 너무 많음')




글로벌, 고객 및 사용자별로 허용 가능한 속도 제한을 부과하여 클러스터의 사용성에 영향을 줄 수 있는 남용을 방지하세요. 웹 애플리케이션 방화벽 (WAF)을 추가하는 것도 필요합니다. 최근에는 암호화된 HTTPS 데이터를 푸시하여 요청을 실행하는 결정을 서버가 아닌 방화벽이 내리는 데 영향을 미치지 않는 경우가 있습니다.

이러한 조치를 취하면 남용을 방지하고 K8s 클러스터가 받는 부하를 제어할 수 있습니다.

![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_7.png)

이렇게 함으로써 WAF가 원치 않는 요청을 차단할 수 있습니다. 다양한 수준에서의 속도 제한은 고객 및 사용자의 요청 남용을 제어하여 클러스터가 지나치게 많은 부하를 처리하지 않도록 합니다. 물론 클러스터 수준에서 불필요하게 차단하길 원치는 않지만, 그 지점에 도달하면 클러스터가 이미 불안정할 수 있습니다. 따라서 모든 요청을 대규모로 실패시키는 것보다 429 상태 코드를 반환하는 것이 나은 대안입니다.

# 2. 소켓 이벤트 트래픽 제어하기



모든 메이저 웹 애플리케이션은 현재 서버에서 브라우저로 푸시 알림을 받습니다. 브라우저가 거의 실시간 데이터를 받을 수 있다는 것이 멋지다고 생각하지만, 그것들은 전통적인 데스크톱 애플리케이션처럼 보이고 느끼게 만들어줍니다. 그러나 브라우저는 아니라는 것을 명심해야 합니다.

가끔 앱의 능력에 대해 잘못된 가정을 할 때도 있습니다.

"우리 서버는 백엔드에서 수천 개의 이벤트를 처리할 수 있어요." 네... 그런데 당신의 고객 브라우저는 그것을 처리할 수 있을까요? 고객의 머신은 서버가 아닙니다. 그들은 서버와 같은 처리 능력과 메모리를 가지고 있지 않습니다. 클라이언트 측에서 동일한 처리 능력을 모방하려고 한다면 실패로 이어질 것입니다.

![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_8.png)



푸시 알림은 최선을 다해 전달되어야 합니다: 프론트엔드로 이벤트를 전송하려고 노력하지만 보장할 수는 없습니다.

고객이 백만 개의 업데이트를 생성하는 시나리오에서는 브라우저로 그만큼의 이벤트를 전달하려고 시도조차 해서는 안 됩니다. 이렇게 하면 대량의 데이터가 브라우저로 전송되어 플러시하는 데 몇 분 또는 심지어 몇 시간이 걸릴 수 있으며 네트워크 레이턴시에도 영향을 미칠 수 있습니다. 결국 좋은 대역폭을 갖춘 곳도 있고 강력한 컴퓨터를 갖춘 곳도 모두가 아니기 때문입니다.

마지막으로 이처럼 많은 정보를 고객의 브라우저로 전달하는 것은 비용이 들 수 있습니다. 일부 데이터 센터는 외부 트래픽에 대해 요금을 부과하기 때문입니다.

가끔은 이러한 이벤트를 듣고 있는 컴포넌트가 있어 업데이트되고 다른 요청을 만들기도 합니다. 몇몇 업데이트는 더 많은 요청을 만들어 눈덩이 효과를 낼 수 있습니다. 때로는 컴포넌트를 숨기지만 계속 청취하도록 유지하는 경우도 있으며, 이로 인해 이벤트 당 렌더링을 생성해 보이지 않게 될 수도 있습니다.



그래서, 그 대신 어떻게 해야 할까요?

### 아웃바운드 트래픽 속도 제한

너무 많은 데이터를 밀어넣으면 고객의 브라우저와 네트워크가 느려지고 비용이 증가합니다. 그래서 데이터를 수용 가능한 수준으로 유지해야 합니다. 특정 사용자가 여러 브라우저나 탭으로 인한 여러 연결을 가지고 있다면 연결 수로 속도 제한을 나누어 사용자로부터 푸시되는 데이터 양을 제어할 수 있습니다.

## 서버 측 이벤트 삭제



과거 몇 분 이전의 이벤트는 삭제합니다. 이는 데이터가 쌓여 시작될 때 즉시 데이터를 버린다는 의미입니다. 비상 이벤트는 어떻게 할까요? 우리는 중요한 데이터를 일회용이 아닌 것으로 취급해야 합니다. 그러나 브라우저에서 받아야 할 소규모의 중요한 데이터 묶음에 대해서는 그렇지 않습니다. 예를 들어, 작업 확인과 같은 이벤트들은 다른 이벤트들보다 먼저 도착할 수 있도록 우선순위 레인이 있어야 합니다.

![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_9.png)

## 모든 필요한 데이터를 보내기

모든 필요한 데이터는 이벤트의 일부여야 합니다. 프론트엔드는 알림을 받은 후 추가 요청을 하지 말아야 합니다. 그렇게 하면 이벤트에 기반한 비선형 요청이 발생합니다. 하나의 이벤트가 도착하면 한 번의 요청을 보내지만, 100k개의 이벤트를 받으면... 문제가 생길 수 있습니다. 특히 수천 명의 활성 사용자가 있는 경우 더욱 그렇습니다.



API 요청을 관리하는 API 클라이언트를 사용하고, 브라우저 측에 가까운 캐시를 유지하여 일정 기간 동안 데이터를 유지하고 동일한 데이터에 대한 반복적인 호출을 피하세요. 가능하면 일부 전역 구성을 사용해주세요.

![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_10.png)

## 대기 중인 숨겨진 구성 요소를 준비하세요

데이터를 수신하지만 다시 보이고 마지막으로 다시 렌더링 될 때까지 렌더링을 건너뛰세요. 여러 이벤트를 보내고 여러 숨겨진 구성 요소를 렌더링하는 경우, 쓸모없는 구성 요소를 렌더링하여 브라우저 성능에 영향을 줍니다.



싱글 페이지 애플리케이션도 잘못된 아키텍처 결정으로 성능 문제가 발생할 수 있어요. 데이터와 뷰를 분리해서 업데이트하면서 뷰를 렌더링하지 않고 업데이트할 수 있어요.

![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_11.png)

# 3. 자체 프런트엔드 DDoS (분산 서비스 거부)

때로는 개발자들이 영향을 인식하지 못하는 경우가 있어요. 토론이나 회의 중에 나타나는 몇 가지 사소한 문제들이 있어요.



"내 컴포넌트에 추가 요청을 딱 하나만 넣었어요."

딱 한 개죠? 실제로, 그 컴포넌트가 다른 사용자에게 표시되는 횟수에 따라 다를 수 있습니다. '단 하나'의 추가 요청이 기능을 망가뜨린 것은 처음이 아닙니다. 왜냐하면 그 요청으로 많은 요청이 생성되어 기능이 그렇게 많은 요청을 처리할 준비가 되어있지 않았기 때문입니다. 실제로 라이브로 이를 배포하면 거의 즉시 망가질 것입니다. 또한 사용되는 페이지와 트래픽 양에 따라 달라집니다.

"내 React 컴포넌트는 내부 상태에 예상치 못한 케이스가 있어서, 지속적인 렌더링으로 인해 API 호출 무한 루프에 빠졌어요."

이를 수천 명의 고객들에 대해 곱한다면, 모든 것이 다운될 것입니다. 재밌는 점은 수정을 배포했다 하더라도, 브라우저가 이를 감지하고 Javascript를 새로 고칠 때까지 시간이 걸릴 것이며, 이러한 사고를 완전히 해결하기가 어려울 수 있습니다.



"브라우저 DOM에 일부 구성 요소를 캐시하기로 결정했습니다."

이론적으로는 괜찮아요. 이론상으로는요!

대부분의 경우에는 숨겨진 구성 요소들이 계속 백그라운드에서 작동하여 이벤트를 수신하고 렌더링하며, 비록 보이지는 않지만 계속 작업을 수행합니다. 더 나쁜 경우에는 때로는 요청이 필요하지 않은 상태로 계속 발생하기도 합니다. 이런 일이 반복되면 모든 것을 느리게 만드는 충분한 수의 요청이 생성됩니다. 이러한 이벤트들이 숨겨진 구성 요소와 API 호출과 결합되면, 완벽한 슬로우다운 현상이 발생합니다: 앞단과 뒷단에서의 느림 현상이 발생합니다.

단일 요청이 문제가 될 수 없을 것 같죠? 그러나 규모를 고려할 때, 수천 명의 사용자가 있는 상황에서는 요청이 수천 개로 변합니다. 그 영향의 크기는 여러 요소에 의해 달라집니다. 해당 구성 요소가 주요 페이지에 사용되는지 혹은 사용자가 많이 이용하는 페이지에 있는지 여부는 어떨까요? 백엔드가 그러한 요청을 처리할 수 있는지? 데이터베이스에 캐싱이 되어 있어서 데이터베이스에 접근할 필요가 없는지? 데이터베이스에는 이러한 요청을 처리할 복제본이 있는지? 프론트엔드 코드가 예기치 않은 시나리오를 방지할 만큼 충분히 커버리지가 되어 있는지?"



이 문제를 어떻게 완화할 수 있는지 알아보겠습니다.

## 요청의 적절한 수를 처리할 수 있도록 기능을 준비하세요

캐싱을 추가하고, 계산을 해서 적절하게 확장하세요. 데이터베이스가 도움 없이 모든 요청을 처리할 수 있다고 가정하지 마세요.

## 프론트엔드 구성 요소에는 좋은 코드 커버리지가 필요합니다



그렇지 않으면 모든 상황에서 잘 작동하지 않을 수 있습니다. 이는 앱을 충돌시킬 수 있는 무한 루프를 발생시킬 수 있습니다. 이러한 무한 루프는 모든 브라우저에서 Javascript 코드를 무효화해야 하기 때문에 감지하고 되돌릴 때 매우 어려울 수 있습니다.

## 충분한 경고가있는 서비스 또는 엔드 포인트 지표

일주일 동안 종단점이 일반적으로 받는 요청의 주간 이동 평균을 계산하고 시간당 청크로 나누세요. 이제 시간별 이동 평균을 사용하세요.

![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_12.png)



마크다운 형식으로 테이블 태그를 변경하실 수 있습니다.



두 값을 나누면 예상 최대 및 최소 비율이 나오는데, 이는 적응성이 있고 시간에 따라 요청 변동을 따릅니다. 이 비율은 시간당 요청이 주간 요청을 초과하거나 이하한 빈도를 신호합니다.

<img src="/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_13.png" />

```js
(sum(increase(docbase_api_web_request_count{service="docbase-api"}[1h]))) / 
(sum(increase(docbase_api_web_request_count{service="docbase-api"}[1w]))/7/24)
```

이제 이러한 요청에 대한 알림을 생성할 수 있습니다. 예를 들어, 임계값을 3.5 또는 4로 설정하면 트래픽의 예상치를 초과하는 경우에 알림을 받게 됩니다 (차트에서 지난 주에는 3을 넘지 않았음을 볼 수 있습니다). 요청 수에 기반한 알림을 설정하는 경우, 트래픽 패턴이 변경될 때마다 요청 번호를 업데이트해야 합니다.



이 알림을 만들면 일반적으로 감지하기 어려운 트래픽 변화를 모니터링할 수 있습니다. 특히 자체 생성된 DDoS 공격의 경우, 합법적이고 인가된 트래픽이라도 감지하는 데 몇 주가 걸릴 수 있습니다.

# 최종 메모

K8s는 때로 잘못 사용되거나 제대로 이해되지 않을 수 있지만, 좋은 도구입니다. 이를 사용하는 것은 쉽지만, 우리가 원하는 대로 확장하는 것은 훨씬 복잡하며, 예상과 달리 일어나면 혼란스럽고 당황스럽게 만들 수 있습니다.

K8s를 사용할 때 제안하는 바는 상식을 사용하는 것입니다. 상상력을 발휘하고 무엇이 일어나고 있는지, 어떻게 개선할 수 있는지 스스로에게 물어보고, 물론 규모에 맞게 생각하는 것입니다. 그냥 요청만 하는 것이 아닙니다. 그냥 구성 요소만 있는 것이 아닙니다. 모든 것이 제대로 최적화되지 않거나 고려되지 않으면 큰 영향을 줄 수 있습니다.




적절한 도구를 갖추는 것도 매우 중요해요. 추적을 위해 Tempo를 사용하고, 로깅을 위해 Loki를 사용하며, 메트릭 및 경고를 위해 Grafana를 사용하세요. 이 도구들이 없다면, 기본적으로 맹목적일 거예요. K8s를 작동시키려면 백엔드에 OpenTelemetry를, 프론트엔드에는 Faro와 같은 RUM(실 사용자 모니터링) 도구를 사용해야 해요.

쿠버네팅을 즐기세요.

(계속됨…)

참고 문헌:



https://www.meetup.com/pipedrive-talks-lisbon/events/299275446/

https://medium.com/dev-beinfra/k8s-pt-4-deployment-istio-aks-33201db9156a
https://www.rawpixel.com/image/12649860/bomb-explosion-effect-png-transparent-background