---
title: "RocksDB를 사용한 서버 부팅 속도 최적화"
description: ""
coverImage: "/assets/img/2024-05-16-ServerbootstrapoptimizationusingRocksDB_0.png"
date: 2024-05-16 03:02
ogImage: 
  url: /assets/img/2024-05-16-ServerbootstrapoptimizationusingRocksDB_0.png
tag: Tech
originalTitle: "Server bootstrap optimization using RocksDB"
link: "https://medium.com/flipkart-engineering/server-bootstrap-optimization-using-rocksdb-3378b5af55dc"
---


# 소개

Flipkart의 검색 인프라에서 Mustang은 SOLR 인덱스를 관리하는 필수 서비스입니다. 현재, 우리는 Flipkart, Grocery, Hyperlocal 및 Shopsy와 같은 다양한 비즈니스 단위에 대응하는 다양한 샤드에서 운영하고 있습니다. 각 샤드는 해당 샤드로 직접 전송되는 데이터 양과 요청 양에 따라 결정된 다양한 복제본을 호스팅합니다.

각 복제본에는 디스크에 저장된 데이터(제품 관련 데이터, SOLR에서 제공)와 판매자별 목록 데이터에 대한 메모리에 저장된 데이터가 포함되어 있습니다. 빠르게 변화하는 속성에 대한 NRT(Near Real-Time) 데이터로, 애플리케이션 구동 시 중앙 집중식 Redis 클러스터에서 데이터를 가져와 메모리에 있는 데이터 구조체가 구축됩니다. 이러한 메모리에 있는 데이터 구조체는 Kafka 파이프라인을 통해 업데이트되어 Redis와 동기화되어 유지됩니다.

![이미지](/assets/img/2024-05-16-ServerbootstrapoptimizationusingRocksDB_0.png)



평균적으로 각 복제본은 약 15 백만 개의 리스트에 대한 데이터를 보유합니다. 부팅 중에 이러한 인메모리 데이터 구조를 구축하는 프로세스에는 약 30~40분이 소요됩니다. 이 프로세스에서 주요 병목 현상은 Redis인데, 배포 중 동시 요청의 증가를 처리하는 데 어려움을 겪습니다 (이 클러스터의 크기가 각 데이터 센터에 거의 400대의 가상 머신에 가깝기 때문).

이 전체 절차는 배포를 크게 늦추어 최소 2일 이상 소요됩니다. 개발자의 생산성뿐만 아니라 적시에 버그 수정을 배포하는 데도 어려움을 겪게 됩니다.

이 블로그에서는 RocksDB를 사용하여 Mustang의 부팅 시간을 최적화하는 방법에 대해 논의합니다.

# 문제 분석



우리 Redis 클러스터는 Mustang 서버가 다시 시작될 때마다 막혔었습니다. 10%의 롤아웃 요인조차도 약 40개의 Mustang 서버가 Redis에 대해 300K 이상의 동시 호출을 하는 결과를 가져왔습니다. 이러한 대규모 동시 요청의 이유는 각 서버의 폴러 스레드 수 및 배치 크기 때문이었습니다.

또한, Redis에서 목록에 대한 데이터를 가져오는 것이 단순한 Redis GET 작업이 아니었습니다. 우리는 Redis에서 목록 POJO를 작성하는 논리를 추상화한 라이브러리를 작성했는데, 이 라이브러리는 다중 동시 호출을 통해 각 속성의 데이터를 얻기 위해 내부적으로 Redis에 대한 요청을 여러 번 보내고 이를 병합하여 단일 POJO를 생성합니다.

예를 들어, 목록과 관련된 제공은 Redis 내에 SET으로 저장되었으며, 서비스 가능 영역의 가용성 데이터는 BITFIELD로 저장되었습니다. 두 데이터를 가져오려면 Redis에 대해 구별된 쿼리가 필요했으며, 응답 구문 분석도 그에 따라 달랐습니다.

문제점을 찾기 위해 아래에서 위로 가는 방식으로 병목 현상을 탐색하는 것은 좋은 선택처럼 보였습니다. 따라서 우리는 Redis부터 시작했습니다.



# Redis 튜닝

각 애플리케이션 서버의 폴러 스레드의 일괄 처리 크기와 스레드 수를 조정해 보았지만 전반적인 성능에는 개선이 없었습니다. 각 일괄 처리의 지연 시간은 조금 줄었지만 전체적으로 처리해야 하는 일괄 처리가 더 많아져 얻는 이점이 상쇄되었습니다.

사용되지 않는 몇 가지 상품 속성을 찾았지만 여전히 상품 POJO의 일부였습니다. 이러한 속성을 POJO에서 제거하니 성능이 조금 향상되었지만 충분하지는 않았습니다.

Redis 클러스터의 각 샤드에 레플리카 수를 늘리는 옵션도 검토했습니다. 이를 통해 더 나은 부하 분산을 얻을 수 있지만 클러스터가 대부분 유휴 상태이고 Mustang 배포 중에만 사용되기 때문에 실용적이지 않았습니다. 여기에 더 많은 리소스를 추가하는 것에 가치가 없다고 판단했습니다.



Redis를 더 최적화하는 것이 어려워서, 우리는 응용 프로그램의 서버 쪽 옵션을 탐색했어요.

# 파일 캐시 생성

아이디어는 Redis로부터 데이터를 한 번만 검색하여 인메모리 데이터 구조를 구축하고, 그 후에는 미래 배포를 위해 로컬로 캐시하는 것이었습니다.

같은 작업을 위한 빠른 POC를 진행하기 위해 우리는 셧다운 후크를 작성했어요. 이 후크는 모든 인메모리 데이터 구조를 로컬 디스크의 별도 파일에 직렬화할 거에요. 시작 시, 응용 프로그램은 로컬에 저장된 데이터를 역직렬화하고 인메모리 데이터 구조를 로드할 거예요.



<img src="/assets/img/2024-05-16-ServerbootstrapoptimizationusingRocksDB_1.png" />

시작할 때는 아이디어가 유망해 보였지만 나중에 다양한 문제가 발생했습니다. 이 중 일부는 아래와 같습니다:

- 저희의 인메모리 데이터 구조는 사실상 코드의 다른 세그먼트(그리고 메모리에서)입니다. 그러나 이들은 모두 상품 목록 데이터에서 파생되었습니다. 한 세그먼트의 직렬화 중에 문제가 발생하면 해당 세그먼트를 다시 불러오지 않고는 복구할 수 없습니다. 이는 단 하나의 파일이 손상되어도 직렬화된 데이터를 모두 폐기하고 Redis로부터 전체 데이터를 다시 부트스트랩해야 한다는 것을 의미합니다.
- 상품 목록 데이터는 각 샤드마다 동일하지만, 이러한 인메모리 데이터 구조는 응용 프로그램 서버 간에 심지어 같은 샤드 내에서도 다를 수 있습니다. 이 차이는 이러한 데이터 구조 내에서 상품 목록을 식별할 때 사용하는 서수의 무작위적인 특성에서 비롯됩니다. 이 상품 목록 서수는 SOLR 색인 파일을 비동기적으로 로드하는 프로세스 동안 먼저 도착한 사람이 우선적으로 생성되기 때문에 결정론적이지 않습니다. 따라서 동일한 샤드의 다른 복제본들 사이에서 직렬화된 파일을 공유하는 것이 불가능합니다.
- 코드가 지저분해 보였던 이유는 직렬화 및 역직렬화를 위해 Jackson을 사용했기 때문입니다. Jackson은 우리 코드에서 정상적으로 작동하기 위해 특정 getter 및 setter를 필요로 합니다. 이는 특히 상속을 다룰 때 또는 간단히 속성을 반환하는 대신 사용자 정의 논리를 포함하는 getter가 이미 있는 경우에 복잡함을 야기했습니다.

이러한 제약으로 인해 더 견고하고 우아한 솔루션이 필요했습니다. POC를 기반으로 내장 데이터베이스 접근 방식이 유망해 보였고 우리는 결국 RocksDB를 선택하게 되었습니다.



# RocksDB가 당신을 구해줍니다

## 왜 RocksDB를 선택했나요?

우리가 RocksDB를 선택한 이유를 이해해 봅시다.

- 이는 내장형 데이터베이스입니다. 이는 중앙 서버에서 실행할 필요가 없음을 의미합니다. 라이브러리로 직접 코드에 사용할 수 있습니다. 우리는 중앙 집중형 솔루션에서 벗어나려고 했기 때문에, 이것은 우리에게 완벽했습니다.
- 당신의 요구에 맞게 튜닝할 수 있는 구성 옵션을 제공합니다.
- 다양한 작업 부하에서 테스트할 때 유망한 결과를 보았으며, 이는 그 성능에 대한 우리의 신뢰를 높였습니다.
- 이는 매우 인기 있는 데이터베이스이며 다양한 산업에서 사용되고 있습니다 (X가 비슷한 문제를 해결하기 위해 어떻게 사용하는지, Cloudflare가 어떻게 사용하는지, MySQL과의 통합하여 저장 엔진으로 사용하는 방법 확인 등)
- 페이스북이 유지 관리하는 매우 활발한 커뮤니티 지원이 있습니다.



이 데이터 포인트들은 좋은 임베디드 데이터베이스를 선택하는 데 도움이 많이 되었어요. 

## RocksDB의 저장 스키마

임베디드 데이터베이스 선택을 결정하고 나면 코드에 통합하는 작업을 진행했어요. 이 작업은 간단했어요. 우리는 Redis에서 데이터를 한 번 가져와서 이후 배포에서 로컬로 저장된 데이터를 사용할 수 있도록 RocksDB에 저장하고 싶었어요. 

![RocksDB를 사용한 서버 부트스트랩 최적화](/assets/img/2024-05-16-ServerbootstrapoptimizationusingRocksDB_2.png)



간단하게 유지하기 위해 우리는 간단한 저장 스키마를 설계했습니다. RocksDB의 각 행은 단일 목록의 데이터를 포함했습니다. 각 행의 키는 목록의 ID이었고 값은 직렬화된 목록 POJO였습니다. 다음과 같이 보였습니다:

```js
“LISTING_1": “{\"attribute_1\": \"value_1\", \"attribute_2\": \"value_2\"}"
```

단순함 외에도 이러한 종류의 스키마를 선택한 주된 이유 중 하나는 작업의 세분화였습니다. 이 스키마를 사용하면 필요에 따라 단일 목록 또는 그룹의 목록을 업설 또는 가져올 수 있었습니다. RocksDB에 일부 목록의 데이터가 없는 경우 Redis에서 누락된 레코드를 다음 부트스트랩 단계에서 가져와 RocksDB를 업데이트할 수 있습니다. 시스템은 자가 치유 기능을 제공합니다.

이것이 우리 솔루션의 기초를 놓은 것이지만, 아직 해결해야 할 많은 문제가 있었습니다. 다음 섹션에서 몇 가지 다른 어려움에 대해 이야기하겠습니다.



## 고요한 데이터 문제 해결

Redis에서 데이터를 한 번 가져와 로컬에 저장하는 것만으로는 비즈니스의 빠르게 변화하는 성격 때문에 충분하지 않았습니다. 플립카트의 대부분 비즈니스 요구 사항은 목록 속성에 일부 변경이 필요했으며(인메모리 데이터 구조에 대한 비슷한 스키마 변경 포함), 그래서 그럴 때마다 RocksDB에 저장된 데이터는 애플리케이션의 스키마와 호환되지 않게 되었습니다.

이 문제를 해결하기 위해 RocksDB에 인메모리 데이터 구조의 스키마 해시를 리스트 데이터와 함께 저장했습니다. 이 스키마는 배포가 발생할 때 최신 스키마(코드에 저장된)와 비교됩니다. 스키마 불일치가 발생하면 RocksDB 데이터를 단순히 폐기하고 Redis에서 최신 데이터로 다시 채웁니다.

이 방법은 괜찮았지만, 결과적으로 서면 배포의 60%가 데이터 구조 변경을 포함했다는 것이 밝혀졌습니다. 이는 여전히 대부분의 배포에서 Redis에 의존하고 있다는 것을 의미했으며, 이는 이상적이지 않았습니다.



우리는 더 나은 계획을 세웠어요. 동일한 샤드 내의 모든 레플리카가 동일한 목록 데이터를 가지고 있다는 사실을 알고 있었죠. 그래서 왜 각 샤드의 단일 무작위 레플리카로부터 RocksDB 데이터를 생성하여 GCS에 저장한 다음 해당 샤드의 다른 레플리카에 사용하지 않을까요?

이 방법을 구현하는 것은 쉬웠어요. 우리는 코드에 유효성 검사 레이어를 작성해뒀는데, Mustang 시작 시 스키마 해시를 비교할 수 있도록 했어요. 동일하다면 응용 프로그램은 RocksDB에서 데이터를 로드하지만 다르다면 해당 응용 프로그램은 로컬 RocksDB 데이터를 삭제하고 GCS에서 최신 데이터를 가져와서 계속해서 RocksDB에서 데이터를 로드해요.

GCS에 데이터가 없을 경우 Redis로 데이터를 부트스트랩합니다. 배포 파이프라인도 이러한 유형의 배포를 처리하도록 변경되었어요. 스키마 변경이 있을 때마다 CI 파이프라인이 각 샤드에서 무작위 레플리카를 선택하여 최신 코드를 배포하고 Redis에서 부트스트랩한 다음 로컬 RocksDB 데이터를 GCS에 업로드합니다. 나머지 레플리카는 로컬 데이터가 무효화될 때 자동으로 GCS에서 데이터를 가져와요.

## Kafka 업데이트 처리



카프카에서 업데이트를 다룰 때, RocksDB의 데이터가 Redis에 있는 것과 함께 최신 상태를 유지해야 했습니다. 우리는 이 프로세스를 최적화하기 위해 카프카 업데이트를 가로채고 그것을 RocksDB에 추가한 후 메모리 데이터 구조의 변경 사항을 반영하는 전용 클래스를 개발했습니다.

우리는 전체 POJO를 RocksDB에 저장했기 때문에 데이터를 업데이트하기 위해 읽기-수정-업데이트 작업을 수행해야 했습니다. 주요 기술적 장벽은 RocksDB 내에서 잠재적인 업데이트 실패를 관리하여 Mustang이 다음 재시작 시 RocksDB에서 가장 최신 데이터를 검색할 수 있도록 보장하는 데 있었습니다.

이를 완화하기 위해 우리는 try-catch 블록 내에서 오류 처리를 구현했습니다. 어떤 이유로든 업데이트가 실패하면 해당 목록을 간단히 RocksDB에서 삭제했습니다. 삭제 실패의 드문 경우(다시 시도 후에도)를 대비하여 종료시 전체 RocksDB 데이터 세트를 지우기로 선택했습니다. RocksDB 업데이트가 실패하더라도 사용자에 대한 데이터 불일치가 없도록 메모리 데이터 구조를 업데이트했습니다.

해결해야 할 또 다른 문제가 있었습니다. RocksDB의 부트스트랩 후 카프카 이벤트를 가장 최신 오프셋에서 읽기 시작하는 Mustang의 경우(기존 시스템의 기본 동작 방식)에는 데이터 손실이 발생할 수 있습니다. 이는 RocksDB가 Mustang이 재시작하는 동안 업데이트를 받지 못하기 때문입니다. 그 전에는 Mustang이 소스의 진실인 Redis에서 부트스트랩을 했기 때문에 가장 최신 카프카 오프셋에서 읽기를 안전하게 시작할 수 있었던 것이었습니다.



이 문제를 해결하기 위해 우리는 종료할 때 모든 파티션의 Kafka 오프셋을 RocksDB에 저장하기 시작했습니다. 그런 다음 시작할 때 Mustang은 해당 파티션의 저장된 오프셋으로 다시 이동하였습니다. 응용 프로그램 충돌과 같은 이유로 RocksDB에서 오프셋을 찾을 수 없는 경우, 로컬 덤프를 폐기합니다. 또한 현재 오프셋과 저장된 오프셋 간의 차이가 상당히 큰 경우 로컬 덤프도 폐기합니다. 이 결정은 이러한 중요한 데이터 갭을 다시 채우는 데 상당한 시간이 걸릴 것으로 이해하고 기준이 됩니다. 이 차이에 대한 임계값은 Mustang이 일반적으로 다섯 분 동안 처리할 수 있는 업데이트 양을 추정하여 결정됩니다.

## 사용 사례에 맞게 RocksDB 조정

이 시점까지 우리는 RocksDB를 우리의 코드베이스에 성공적으로 통합할 수 있었습니다. Mustang이 인메모리 데이터 구조를 부팅하는 데 걸리는 시간은 30분에서 15분으로 줄었습니다. 우리는 우리의 액세스 패턴을 더 잘 이해하고 RocksDB의 내부를 깊이 파고들면 RocksDB에서 더 많은 성과를 얻을 수 있다고 믿었습니다.

우리의 워크로드는 쓰기와 읽기의 혼합물이었습니다. Redis에서 데이터를 부팅하고 RocksDB에 삽입하는 동안은 완전히 쓰기 중심이지만 이후 배포에서는 항상 읽기 중심입니다. 이러한 패턴 중 하나에만 최적화할 수 있었고, 우리는 읽기를 최적화하기로 결정했습니다 (당연한 이유로).



아래는 저희 케이스에 작동한 몇 가지 최적화 내용입니다:

- 캐시 비활성화: LRU 기반 블록 캐시는 모든 RocksDB 사용 사례에서 사용하는 것이 좋지만 심한 락 경합이 발생합니다. 부팅 중에 한 번만 목록을 읽는 경우에는 데이터 블록의 캐시를 비활성화했습니다.
- 레벨 컴팩션 사용: 레벨 컴팩션 전략은 크기 단위(일명 유니버설) 컴팩션 전략보다 읽기 및 공간 증폭면에서 더 나은 결과를 줍니다.
- LSM 트리의 레벨 수 줄임: LSM 트리의 레벨 수는 RocksDB에서 중요한 속성입니다. LSM 트리에 존재할 레벨 수를 결정합니다. 데이터 중 일부가 핫하게 액세스되는 경우 레벨이 많으면 유익하지만, 액세스 패턴이 무작위인 경우 읽기 대기 시간에 영향을 줄 수 있습니다. 우리의 경우에는 레벨 수를 기본값인 7에서 3으로 줄였습니다.
- 주기적인 전체 컴팩션 트리거: RocksDB는 최상태일 때 가장 잘 작동합니다. 읽기 성능을 최적화하기 위해 카프카 업데이트로 인한 읽기(및 공간) 증폭을 줄이기 위해 매일 취침 시간에 전체 컴팩션을 수동으로 트리거하는 비동기 스레드를 작성했습니다.
- WAL 비활성화: 기본적으로 RocksDB는 모든 쓰기를 WAL에 메모리 테이블과 함께 저장합니다. 데이터가 손실되지 않는 자가 치유하는 성격의 경우 WAL을 비활성화했습니다.
- multiGet()을 사용하여 데이터 읽기: RocksDB는 DB에서 데이터를 읽는 다양한 방법을 제공합니다. get() 명령 또는 multiGet() 명령을 실행할 수 있습니다. multiGet()은 다중 get() 호출에 비해 더 효율적이며, 필터/인덱스 캐시에서 적은 스레드 경합, 내부 메서드 호출 수 감소, 다른 데이터 블록에 대한 IO에 대한 더 나은 병렬화 등 여러 이유로 선호됩니다.
- 목록 정렬 및 일괄 처리: 전체 목록 세트를 정렬한 다음 RocksDB에서 데이터를 가져오기 전에 이를 작은 일괄 처리로 만들었습니다. 정렬된 목록은 디스크에서 동일한 또는 근접한 페이지에 있을 가능성이 크기 때문에 랜덤 디스크 IO를 줄였습니다.

이러한 최적화로 부팅 시간을 15분에서 약 6분으로 대폭 단축하여 효율을 높이는 우리의 노력에서 중요한 성과를 도출했습니다.

자세한 내용은 이 튜닝 안내서를 읽어보세요.



# RocksDB를 운영 환경으로 이끌기

모든 것이 준비된 상태에서 우리는 RocksDB를 운영 환경으로 적용하고 싶었습니다. 그러나 스택에 새로운 기술을 도입하는 것은 어떠한 중단도 방지하기 위해 조심스럽게 진행해야 했습니다. Mustang이 RocksDB와 어떻게 상호 작용하는지 모니터링하기 위한 적절한 메트릭을 도입하고 위험을 완화하는 방법을 구현했습니다. 그런 다음, 각 샤드 내의 일부 레플리카에 대한 제한적인 배포를 시작했습니다.

## 작은 결함

몇 개의 Mustang 서버에 최신 코드를 배포한 직후, 응답 시간이 저하되는 현상이 발생하기 시작했습니다. 더 깊게 파고들어보니, 몇 일 동안 전체 VM의 메모리가 천천히 소비되는 것을 발견했습니다. 이 과도한 메모리 사용은 Solr의 인덱스 관련 파일을 캐싱하는 능력을 방해하여 런타임 중 과도한 디스크 이용률을 초래하여 지연 시간을 증가시켰습니다. Java 어플리케이션이 이 메모리 누수를 발생시킬 수 없다는 것은 명백했습니다. 왜냐하면 Java 어플리케이션은 시작 시에 고정된 메모리 청크(힙 메모리 형태로 할당)만 할당되고, 그 위에 JVM이 기능하기 위해 약간의 추가 네이티브 메모리만 사용하는 것 뿐이기 때문입니다. (JVM이 사용하는 네이티브 메모리를 확인하는 방법은 이 가이드를 참조하세요)



의심이 RocksDB로 향했는데, 내장 데이터베이스로 분류되었지만 Java 라이브러리뿐만 아니라 C++ 구성 요소도 포함되어 있고 JNI를 통해 Java 애플리케이션과 상호 작용하는 것으로 확인되었습니다. Java에서 RocksDB와 상호 작용하는 클래스들은 내부적으로 RocksDB의 C++ 대응물을 호출합니다. C++의 메모리 관리는 자동 가비지 콜렉션 시스템이 없어서 어려워요. 우리는 초반에 RocksDB에 버그가 있을거라고 생각했어요.

그때부터 우리는 네이티브 메모리 누수를 디버깅할 수 있는 옵션을 탐색하기 시작했어요. 네이티브 메모리 누수를 찾아가는 우리의 여정은 블로그로서 충분히 소개할 만한 주제였지만, 간결함을 위해 이 자리에서 우리가 도움을 받은 내용에 대해서만 이야기할 예정이에요.

이러한 유형의 메모리 누수를 디버깅하기 위해 우리는 Jeprof라는 도구를 발견했어요. 이 도구는 JNI 호출과 같은 이유로 발생하는 네이티브 메모리 할당을 추적하는 데 사용됩니다. 그래서 우리는 Jeprof를 구성하여 애플리케이션의 네이티브 메모리 할당에 대한 메모리 덤프를 수 분마다 수행하도록 설정했어요. 나중에 우리는 몇 시간 간격으로 생성된 2개의 무작위 덤프를 비교하여 어떤 객체가 크기가 커지고 있는지 확인했어요. 같은 내용의 일부를 아래에 기술한 내용을 참고해 주세요:

![이미지](/assets/img/2024-05-16-ServerbootstrapoptimizationusingRocksDB_3.png)



스크린샷을 보면, RocksDB에서 제공된 ReadOptions()와 WriteOptions() 객체들이 많이 할당되었음을 확인할 수 있었습니다.

코드를 확인해본 결과, 이 두 클래스에 대한 새로운 객체 할당이 발생하는 곳은 하나뿐이었습니다. 우리 코드에서 RocksDB 관련 구성을 처리하기 위해, ReadOptions()와 WriteOptions()와 같은 다양한 객체를 보유하고 이를 맵에 다양한 열 패밀리 이름에 매핑하는 새 클래스를 만들었습니다. 이러한 객체들은 일반적으로 Mustang 시작 시 제공되며 다시 생성되지 않습니다.

그러나 안전을 위해, 열 패밀리에 요청되었을 때 이미 사용 가능한 객체들이 없는 상황을 처리하기 위한 해결책을 마련했습니다. 우리는 Map의 getOrDefault() 메서드를 활용하여, 미리 구성된 객체를 검색하거나 지정된 열 패밀리에 대해 실행 중에 새로운 객체를 생성할 수 있도록 했습니다. 이 구현에 대한 자바 코드는 아래와 유사했습니다:

```java
...
public ReadOptions getReadOptionsByColumnFamily(String columnFamilyName) {
  return this.readOptions.getOrDefault(columnFamilyName, new ReadOptions());
}

public WriteOptions getWriteOptionsByColumnFamily(String columnFamilyName) {
  return this.writeOptions.getOrDefault(columnFamilyName, new WriteOptions());
}
...
```



## 그럼 왜 메모리 누수를 발생시킬까요?

RocksDB의 메모리 관리에 관한 문서를 읽어보니, RocksDB의 각 클래스가 Autocloseable을 직간접적으로 구현한다는 것을 알게 되었습니다. RocksDB의 자바 객체에서 실제 메모리를 해제하기 위해 사용이 완료되면 명시적으로 close()를 호출해야 합니다 (또는 try-with-resources를 사용). 이를 하지 않으면 메모리 누수가 발생할 수 있습니다.

위의 코드 조각에서 언급된 로직을 구현하는 과정에서, Map의 getOrDefault() 내에서 새 객체가 생성되고 있음을 인지하지 못했습니다. 그 함수가 호출될 때마다 사전 구성된 객체가 주어진 칼럼 패밀리를 위해 존재하는지 여부와 관계없이 이러한 새로 생성된 객체는 닫히지 않고 메모리 누수에 기여했습니다.

메모리 누수의 근본 원인을 이해한 후, 문제 해결은 쉬웠습니다. 이 구성 클래스를 인스턴스화하는 동안 기본 ReadOptions 및 WriteOptions 객체를 한 번만 만들어서 Map의 getOrDefault()에서 새 객체를 생성하는 대신 이들을 사용했습니다.



영향을 받은 Mustang 서버에 대한 수정 사항을 신속하게 배포하고 메모리 안정성을 확인하기 위해 한동안 모니터링했어요.

## 배포 계속 진행

RocksDB의 부정적인 영향이 없고 모든 것이 원활히 작동하는 것을 확인한 후, 시스템 자원에 특별히 주의를 기울이면서 남은 Mustang 서버를 배포하기로 했어요. 이 점진적인 접근법을 통해 우리는 원활한 전환을 보장하고 제품 환경의 안정성을 유지할 수 있었어요.

## 결론



요약하자면, RocksDB는 Mustang의 배포 과정에서 현저한 향상을 이끌어냈습니다. Redis에 의존했던 이전 방식 대비 인메모리 데이터 구조를 부트스트랩하는 데 필요한 시간을 크게 줄였습니다. 

다양한 샤드를 통해 방대한 테스트를 거친 결과, 부트스트랩 시간이 상당히 줄어들었으며 평균 6분으로 안정화되었습니다 (이전 30~40분). 서버 당 부트스트랩 시간뿐만 아니라 배포 속도도 향상되었으며 이제 더 많은 서버를 병렬로 배포할 수 있게 되었습니다.

그 결과, 전체 샤드에 걸친 Mustang의 전체 배포 과정은 이제 3시간 미만이 소요되며, RocksDB 도입을 통해 달성한 효율성 향상의 증거가 되었습니다. 이 성공은 저희 인프라 내 지속적인 개선과 최적화에 대한 헌신을 강조합니다.